#Math #Stadistics 
[[3.3 EDA Detailed Guide]]
# ğŸ”„ Data Transformation Techniques

## ğŸŒŸ IntroducciÃ³n

Las transformaciones de datos son esenciales para preparar y mejorar la calidad de los datos antes de analizarlos o usarlos en modelos de aprendizaje automÃ¡tico. Este documento cubre tÃ©cnicas comunes y avanzadas como normalizaciÃ³n, estandarizaciÃ³n, discretizaciÃ³n y transformaciÃ³n de distribuciones sesgadas.

---

## 1ï¸âƒ£ Data Centering and Scaling

### ğŸ“ Min-Max Normalization (Escalado entre 0 y 1)

```Python
from sklearn.preprocessing import MinMaxScaler
import numpy as np

scaler = MinMaxScaler()
data = np.array([[5], [10], [15]])
scaled_data = scaler.fit_transform(data)
```

- Escala los valores entre 0 y 1.
    
- Ãštil cuando los rangos de atributos son diferentes.
    

### ğŸ“ Standardization (Z-score Scaling)

```Python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
standardized_data = scaler.fit_transform(data)
```

- Convierte los datos para que tengan media = 0 y desviaciÃ³n estÃ¡ndar = 1.
    
- Ãštil cuando se requiere una distribuciÃ³n normal para modelos.
    

ğŸ“Œ **ComparaciÃ³n:**

|MÃ©todo|Rango|Sensible a outliers|Uso tÃ­pico|
|---|---|---|---|
|Min-Max|[0, 1]|SÃ­|Redes neuronales, escalado visual|
|Z-score|Sin lÃ­mite|Menos|RegresiÃ³n, PCA, clustering|

---

## 2ï¸âƒ£ Discretizing Numerical Data and Collapsing Categories

### ğŸ”¢ Binning con `pd.cut()`

```Python
import pandas as pd

ages = [12, 17, 22, 35, 45, 67, 80]
labels = ['Child', 'Young Adult', 'Adult', 'Senior']
binned = pd.cut(ages, bins=[0, 18, 30, 60, 100], labels=labels)
print(binned)
```

### ğŸ”€ Combinar categorÃ­as

```Python
data = pd.Series(['NY', 'CA', 'NY', 'TX', 'CA', 'TX', 'NY'])
mapping = {'NY': 'East', 'CA': 'West', 'TX': 'South'}
collapsed = data.replace(mapping)
print(collapsed)
```

---

## 3ï¸âƒ£ Advanced Data Transformations: Skewed Data

### âš ï¸ Â¿Por quÃ© normalizar distribuciones sesgadas?

- Muchas tÃ©cnicas estadÃ­sticas y modelos ML asumen una **distribuciÃ³n normal**.
    
- Datos sesgados afectan la precisiÃ³n del modelo.
    

### ğŸª™ Ejemplo: precios de casas (right-skewed)

```Python
import pandas as pd
import seaborn as sns
import numpy as np

home_data = pd.read_csv('home_data.csv')
home_prices = home_data['SalePrice']

# VisualizaciÃ³n de la distribuciÃ³n original
sns.histplot(home_prices, kde=True)
print("Skewness original:", home_prices.skew())
```

### ğŸ” Log Transformation con NumPy

```Python
log_home_prices = np.log(home_prices)
sns.histplot(log_home_prices, kde=True)
print("Skewness despuÃ©s del log:", log_home_prices.skew())
```

### ğŸ’¡ Alternativa con `PowerTransformer` de sklearn

```Python
from sklearn.preprocessing import PowerTransformer

pt = PowerTransformer()
home_prices_reshaped = home_prices.values.reshape(-1, 1)
transformed = pt.fit_transform(home_prices_reshaped)
```

---

## âœ… ConclusiÃ³n

- **Estandariza o normaliza** los datos para algoritmos sensibles a escalas.
    
- **Agrupa o recategoriza** valores para facilitar el anÃ¡lisis.
    
- **Aplica transformaciones logarÃ­tmicas** para normalizar distribuciones sesgadas.