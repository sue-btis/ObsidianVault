#Math #Stadistics 
[[3.3 EDA Detailed Guide]]
# 🔄 Data Transformation Techniques

## 🌟 Introducción

Las transformaciones de datos son esenciales para preparar y mejorar la calidad de los datos antes de analizarlos o usarlos en modelos de aprendizaje automático. Este documento cubre técnicas comunes y avanzadas como normalización, estandarización, discretización y transformación de distribuciones sesgadas.

---

## 1️⃣ Data Centering and Scaling

### 📏 Min-Max Normalization (Escalado entre 0 y 1)

```Python
from sklearn.preprocessing import MinMaxScaler
import numpy as np

scaler = MinMaxScaler()
data = np.array([[5], [10], [15]])
scaled_data = scaler.fit_transform(data)
```

- Escala los valores entre 0 y 1.
    
- Útil cuando los rangos de atributos son diferentes.
    

### 📐 Standardization (Z-score Scaling)

```Python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
standardized_data = scaler.fit_transform(data)
```

- Convierte los datos para que tengan media = 0 y desviación estándar = 1.
    
- Útil cuando se requiere una distribución normal para modelos.
    

📌 **Comparación:**

|Método|Rango|Sensible a outliers|Uso típico|
|---|---|---|---|
|Min-Max|[0, 1]|Sí|Redes neuronales, escalado visual|
|Z-score|Sin límite|Menos|Regresión, PCA, clustering|

---

## 2️⃣ Discretizing Numerical Data and Collapsing Categories

### 🔢 Binning con `pd.cut()`

```Python
import pandas as pd

ages = [12, 17, 22, 35, 45, 67, 80]
labels = ['Child', 'Young Adult', 'Adult', 'Senior']
binned = pd.cut(ages, bins=[0, 18, 30, 60, 100], labels=labels)
print(binned)
```

### 🔀 Combinar categorías

```Python
data = pd.Series(['NY', 'CA', 'NY', 'TX', 'CA', 'TX', 'NY'])
mapping = {'NY': 'East', 'CA': 'West', 'TX': 'South'}
collapsed = data.replace(mapping)
print(collapsed)
```

---

## 3️⃣ Advanced Data Transformations: Skewed Data

### ⚠️ ¿Por qué normalizar distribuciones sesgadas?

- Muchas técnicas estadísticas y modelos ML asumen una **distribución normal**.
    
- Datos sesgados afectan la precisión del modelo.
    

### 🪙 Ejemplo: precios de casas (right-skewed)

```Python
import pandas as pd
import seaborn as sns
import numpy as np

home_data = pd.read_csv('home_data.csv')
home_prices = home_data['SalePrice']

# Visualización de la distribución original
sns.histplot(home_prices, kde=True)
print("Skewness original:", home_prices.skew())
```

### 🔁 Log Transformation con NumPy

```Python
log_home_prices = np.log(home_prices)
sns.histplot(log_home_prices, kde=True)
print("Skewness después del log:", log_home_prices.skew())
```

### 💡 Alternativa con `PowerTransformer` de sklearn

```Python
from sklearn.preprocessing import PowerTransformer

pt = PowerTransformer()
home_prices_reshaped = home_prices.values.reshape(-1, 1)
transformed = pt.fit_transform(home_prices_reshaped)
```

---

## ✅ Conclusión

- **Estandariza o normaliza** los datos para algoritmos sensibles a escalas.
    
- **Agrupa o recategoriza** valores para facilitar el análisis.
    
- **Aplica transformaciones logarítmicas** para normalizar distribuciones sesgadas.