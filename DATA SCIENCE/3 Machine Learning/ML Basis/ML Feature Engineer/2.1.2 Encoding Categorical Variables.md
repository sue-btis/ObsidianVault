#Machine_Learning 

# ğŸ§© Encoding Categorical Variables in Python

>**Muchos modelos de machine learning requieren datos numÃ©ricos, por lo que las variables categÃ³ricas deben transformarse**. 

## ğŸ“š Tipos de Variables CategÃ³ricas

- **Nominales**: sin orden lÃ³gico (ej. color, estado).
- **Ordinales**: con jerarquÃ­a (ej. condiciÃ³n de un producto: Nuevo > Bueno > Regular).

---

## 1. ğŸ”¢ Ordinal Encoding

### âœ”ï¸ Â¿CuÃ¡ndo usarlo?
Cuando la variable tiene **orden**, como la condiciÃ³n de un auto.

### ğŸ§ª Ejemplo

```python
rating_dict = {'Excellent':5, 'New':4, 'Like New':3, 'Good':2, 'Fair':1}
cars['condition_rating'] = cars['condition'].map(rating_dict)
```

### ğŸ“¦ Con `OrdinalEncoder` de sklearn

```python
from sklearn.preprocessing import OrdinalEncoder

encoder = OrdinalEncoder(categories=[['Excellent', 'New', 'Like New', 'Good', 'Fair']])
cars['condition_rating'] = encoder.fit_transform(cars['condition'].values.reshape(-1,1))
```

#### Antes/despues
**Antes:**

| condition |
|-----------|
| Excellent |
| Good      |
| Fair      |

**DespuÃ©s:**

| condition | condition_rating |
|-----------|------------------|
| Excellent | 5                |
| Good      | 2                |
| Fair      | 1                |

---



## 2. ğŸ·ï¸ Label Encoding

### âœ”ï¸ Â¿CuÃ¡ndo usarlo?
Para datos nominales con **muchos valores Ãºnicos**, pero **no hay orden**.

```python
# Convertir a categorÃ­a
cars['color'] = cars['color'].astype('category')
cars['color'] = cars['color'].cat.codes
```

### ğŸ“¦ Con `LabelEncoder` de sklearn

```python
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
cars['color'] = encoder.fit_transform(cars['color'])
```

âš ï¸ Puede inducir a modelos a pensar que hay orden entre categorÃ­as.

#### Antes/despues
**Antes:**

| color  |
|--------|
| black  |
| white  |
| blue   |

**DespuÃ©s:**

| color  |
|--------|
| 2      |
| 18     |
| 3      |

---



## 3. ğŸŸ¦ One-Hot Encoding

### âœ”ï¸ Â¿CuÃ¡ndo usarlo?
Para **evitar supuesta jerarquÃ­a** en datos nominales.

```python
ohe = pd.get_dummies(cars['color'])
cars = cars.join(ohe)
```

âœ… Evita malentendidos del modelo.  
âš ï¸ Puede aumentar mucho la dimensionalidad.

#### Antes/despues
**Antes:**

| color  |
|--------|
| black  |
| white  |
| blue   |

**DespuÃ©s:**

| black | white | blue |
|-------|-------|------|
| 1     | 0     | 0    |
| 0     | 1     | 0    |
| 0     | 0     | 1    |

---



## 4. ğŸ”¢ Binary Encoding

### âœ”ï¸ Â¿CuÃ¡ndo usarlo?
Cuando hay **muchas categorÃ­as nominales** y queremos **reducir dimensionalidad**.

```python
from category_encoders import BinaryEncoder

colors = BinaryEncoder(cols=['color'], drop_invariant=True).fit_transform(cars)
```

ğŸ‘ Reduce nÃºmero de columnas  
âš ï¸ No interpretable fÃ¡cilmente

#### Antes/despues
**Antes:**

| color  |
|--------|
| black  |
| white  |
| blue   |

**DespuÃ©s (5 bits):**

| color_0 | color_1 | color_2 | color_3 | color_4 |
|---------|---------|---------|---------|---------|
| 1       | 0       | 0       | 1       | 0       |
| 0       | 1       | 0       | 0       | 1       |
| 1       | 1       | 0       | 0       | 0       |

---



## 5. ğŸ’  Hashing Encoding

### âœ”ï¸ Â¿CuÃ¡ndo usarlo?
Cuando importa el **rendimiento** mÃ¡s que la **interpretabilidad**.

```python
from category_encoders import HashingEncoder

encoder = HashingEncoder(cols='color', n_components=5)
hash_results = encoder.fit_transform(cars['color'])
```

âš ï¸ Puede haber colisiones = pÃ©rdida de informaciÃ³n

#### Antes/despues
**Antes:**

| color  |
|--------|
| black  |
| white  |
| blue   |

**DespuÃ©s (hash = 5 columnas):**

| col0 | col1 | col2 | col3 | col4 |
|------|------|------|------|------|
| 0    | 1    | 0    | 1    | 1    |
| 1    | 0    | 1    | 0    | 1    |
| 1    | 1    | 1    | 0    | 0    |


---



## 6. ğŸ¯ Target Encoding

### âœ”ï¸ Â¿CuÃ¡ndo usarlo?
En tareas **de regresiÃ³n supervisada**. Usa el promedio del target para cada categorÃ­a.

```python
from category_encoders import TargetEncoder

encoder = TargetEncoder(cols='color')
encoder_results = encoder.fit_transform(cars['color'], cars['sellingprice'])
```

âš ï¸ Riesgo de **sobreajuste**

#### Antes/despues
**Antes:**

| color | sellingprice |
|-------|--------------|
| black | 15000        |
| white | 18000        |
| blue  | 10000        |

**DespuÃ©s:**

| color (encoded) |
|-----------------|
| 14769.29        |
| 18048.52        |
| 8458.25         |


---

## â° Encoding de Variables de Fecha y Hora

```python
cars['saledate'] = pd.to_datetime(cars['saledate'])

cars['month'] = cars['saledate'].dt.month
cars['dayofweek'] = cars['saledate'].dt.dayofweek
cars['yearbuild_sold'] = cars['saledate'].dt.year - cars['year']
```

#### Antes/despues
**Antes:**

| saledate           |
|--------------------|
| 2023-05-12 00:00:00|

**DespuÃ©s:**

| month | dayofweek | yearbuild_sold |
|-------|-----------|----------------|
| 5     | 4         | 1              |

---


### Resumen 

| MÃ©todo              | Â¿CuÃ¡ndo usarlo?                       | Pros                         | Contras                       |
|---------------------|----------------------------------------|------------------------------|-------------------------------|
| Ordinal Encoding     | Variables ordenadas                  | Simple, interpretable        | Puede inducir sesgos          |
| Label Encoding       | Nominales simples                    | FÃ¡cil de implementar         | Puede inducir orden falso     |
| One-Hot Encoding     | Nominales sin orden                  | Evita jerarquÃ­a falsa        | Incrementa dimensionalidad    |
| Binary Encoding      | Muchas categorÃ­as                    | Eficiente                    | Menos interpretable           |
| Hashing Encoding     | Modelos rÃ¡pidos, menos interpretaciÃ³n | Muy eficiente                | Colisiones                    |
| Target Encoding      | RegresiÃ³n, correlaciÃ³n con target     | Captura relaciÃ³n directa     | Sobreajuste                   |
