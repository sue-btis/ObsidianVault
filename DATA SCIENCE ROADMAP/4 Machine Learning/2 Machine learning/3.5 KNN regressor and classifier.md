#Machine_Learning 

# üß≠ K-Nearest Neighbors (KNN) 

 What is K-Nearest Neighbors?

**K-Nearest Neighbors (KNN)** is a simple, powerful algorithm used for both **classification** and **regression**. In classification, it works like this:

> To classify a new data point, look at the 'K' closest labeled data points and **vote**.

- **Classification**: Majority vote from nearest neighbors
- **Regression**: Average or weighted average of the neighbors' values

---
## üìê Distance Metric

By default, KNN uses **Euclidean distance**:

$$
d(x, x') = \sqrt{\sum (x_i - x'_i)^2}
$$

Other metrics like Manhattan or Minkowski distance can be used by changing the `metric` parameter.

---

# üß™ How KNN Works (Step-by-Step)
- Normalizing the data
- Training the model
- Testing with different values of K
- Predicting new points

### Choosing the Best K

- **Too small (e.g., K=1)** ‚Üí sensitive to noise (overfitting)
- **Too large (e.g., K=N)** ‚Üí too smooth, may ignore useful patterns (underfitting)

Try several K values and pick the one that works best using cross-validation.

---
## üß≠ Part 1: KNN Classifier

### ‚úÖ Objective:
Predict the class label (e.g., spam or not spam).

### üß™ Full Classifier Example:

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

# Load dataset
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Normalize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train KNN Classifier
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred = model.predict(X_test_scaled)
print(classification_report(y_test, y_pred))
```

---

## üìä Choosing the Best K (Classifier)

Try several values of K using cross-validation to find the one that gives the best performance.

```python
from sklearn.model_selection import cross_val_score

for k in range(1, 11):
    model = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    print(f"K={k}, CV Accuracy: {scores.mean():.2f}")
```

---

## üìà Part 2: KNN Regressor

### ‚úÖ Objective:
Predict a **continuous value** like a movie rating or house price.

### üß™ Full Regressor Example:

```python
import numpy as np
from sklearn.neighbors import KNeighborsRegressor
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

# Load dataset
X, y = fetch_california_housing(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Normalize
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train KNN Regressor with Weighted distance
model = KNeighborsRegressor(n_neighbors=3, weights='distance')
model.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred = model.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")
```

## üßÆ Weighted KNN Regression (Smarter Averaging)

Instead of a simple average, we can use a **weighted average** where closer neighbors have more influence.

### Example:

| Movie | Rating | Distance |
|-------|--------|----------|
| A     | 5.0    | 3.2      |
| B     | 6.8    | 11.5     |
| C     | 9.0    | 1.1      |

- **Simple Mean**: (5.0 + 6.8 + 9.0) / 3 = 6.93  
- **Weighted Average**:

$$
\frac{5.0/3.2 + 6.8/11.5 + 9.0/1.1}{1/3.2 + 1/11.5 + 1/1.1} \approx 7.9
$$

---

## ‚úÖ Summary Table

| Aspect         | Classifier (KNeighborsClassifier) | Regressor (KNeighborsRegressor) |
|----------------|-----------------------------------|----------------------------------|
| Output         | Class label                       | Numeric value                   |
| Final Step     | Majority vote                     | Average / Weighted Average      |
| Common Metrics | Accuracy, F1 Score                | MSE, RMSE, R¬≤                   |
| Weight Option  | `weights='uniform'` or `'distance'` | `weights='uniform'` or `'distance'` |