#Machine_Learning 
[[3.3 Linear Regression OLS vs Gradient Descent]]

# ğŸ“ˆ Multiple Linear Regression 

La **regresiÃ³n lineal mÃºltiple** es una extensiÃ³n de la regresiÃ³n lineal simple donde se utilizan **dos o mÃ¡s variables independientes** para predecir una variable dependiente continua.

---

## ğŸ§  Idea Principal

En lugar de usar una sola entrada $x$, ahora usamos mÃºltiples caracterÃ­sticas $x_1, x_2, ..., x_n$:

$$\hat{y} = b + m_1x_1 + m_2x_2 + \dots + m_nx_n$$

- $\hat{y}$: predicciÃ³n del valor de salida
- $b$: intercepto
- $m_i$: coeficientes que indican cuÃ¡nto influye cada variable $x_i$ en $y$

---

## ğŸ” Â¿CuÃ¡ndo usar regresiÃ³n mÃºltiple?

Cuando el fenÃ³meno que quieres predecir depende de mÃºltiples factores.  
Por ejemplo: predecir el precio de una casa segÃºn su superficie, nÃºmero de habitaciones y ubicaciÃ³n.

---

## ğŸ“Š CorrelaciÃ³n

Antes de entrenar un modelo, conviene revisar si las variables estÃ¡n correlacionadas con la salida:

- **CorrelaciÃ³n positiva**: $r$ cerca de +1  
- **CorrelaciÃ³n negativa**: $r$ cerca de -1  
- **Sin correlaciÃ³n**: $r \approx 0$

Coeficiente de correlaciÃ³n de Pearson:

$$r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 \sum (y_i - \bar{y})^2}}$$

Esto ayuda a decidir quÃ© variables incluir en el modelo.

---

## ğŸ’» CÃ³digo en Python

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import seaborn as sns
import matplotlib.pyplot as plt

# Dataset de ejemplo
data = pd.DataFrame({
    "horas_estudio": [1, 2, 3, 4, 5],
    "horas_sueÃ±o": [8, 7, 6, 5, 4],
    "nota": [60, 65, 70, 75, 80]
})

# Variables independientes y dependiente
X = data[["horas_estudio", "horas_sueÃ±o"]]
y = data["nota"]

# Modelo
model = LinearRegression()
model.fit(X, y)

# PredicciÃ³n
y_pred = model.predict(X)

# Resultados
print("Coeficientes:", model.coef_)
print("Intercepto:", model.intercept_)

#Evaluacion del Modelo
print("RÂ²:", r2_score(y, y_pred))
print("MSE:", mean_squared_error(y, y_pred))

# CorrelaciÃ³n
print(data.corr())

# GrÃ¡fico de correlaciÃ³n
sns.heatmap(data.corr(), annot=True, cmap="coolwarm")
plt.title("Matriz de CorrelaciÃ³n")
plt.show()
```

---

## ğŸ“ EvaluaciÃ³n del Modelo

### âœ… RÂ² (Coeficiente de determinaciÃ³n)

$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$$

- Mide quÃ© tan bien el modelo explica la variabilidad de los datos.
- Valor ideal: cercano a 1.  
- Si $R^2 = 0.9$, el modelo explica el 90% de la variaciÃ³n.

---

### âœ… MSE (Mean Squared Error)

$$MSE = \frac{1}{n} \sum (y_i - \hat{y}_i)^2$$

- Valor ideal: cercano a 0.
- Ãštil para comparar modelos.

---

## ğŸš¨ Cuidado con:

- **Colinealidad**: cuando dos variables explican lo mismo, pueden distorsionar los coeficientes.
- **Sobreajuste (overfitting)**: cuando tu modelo es muy preciso en los datos de entrenamiento pero falla con nuevos datos.
- **Datos categÃ³ricos**: se deben convertir a variables numÃ©ricas (One-Hot Encoding).

---
## ğŸ§  Recomendaciones

- Usa `corr()` para elegir variables relevantes.
- Visualiza con `sns.heatmap()` o scatter plots.
- EvalÃºa modelos con mÃºltiples mÃ©tricas, no solo RÂ².
- Prueba con datos nuevos (validaciÃ³n cruzada si es posible).

